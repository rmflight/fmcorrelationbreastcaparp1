# Calculating the lower limit of the error of the reads

In doing some of the exploratory analysis and examining replicates, a bunch of the regions in the PARP1 data have low counts, ~ 10, where it appears that the correlative structure breaks down. This can be seen in plotting the replicates against each other. Ideally, we might be able to simply provide a minimum value to the function that calculates the correlations, but we first need to be able to justify the minimum value that we are using. To do that, we need to be able to show where the correlation breaks down. Although initially seen in the PARP1 data, we will also do a similar analysis for all the data sets that consist of replicates, including methylation and CTCF binding.

```{r setup}
data_dir <- "/mlab/data/rmflight/Documents/projects/work/fondufe-mittendorf_lab/parp1_data"
graph_dir <- "/mlab/data/rmflight/Documents/projects/work/fondufe-mittendorf_lab/parp1/graphs"
library(GenomicRanges)
library(magrittr)
options(mc.cores = 10)
library(parallel)
library(ggplot2)
library(parp1)
library(BiocParallel)
library(BSgenome.Hsapiens.UCSC.hg19)
library(pracma)
library(fmdatamcf7parp1)
```

Because we have a lot of points, and `RStudio` takes time to get the plots, we will open an `X11` plot window to send the plots to.

```{r plotX11}
X11()
```

## Correlation Changes by Adding Centiles

As a check on the data, we will divide the data up into **centiles** (quantiles of 100), and then starting at the low end, calculate the correlation, add the next centile of points, calculate the correlation again, and so on until we have all the points. In addition, we will do the same starting at the high end, and iteratively adding points. This should show us where the correlation starts to stabilize, and which points should probably be removed.


### PARP1

```{r load_parp1}
data(parp1_ln4_unique)
data(parp1_ln5_unique)
genome_tiles <- tileGenome(seqinfo(Hsapiens), tilewidth = 2000, cut.last.tile.in.chrom = TRUE)
```

In this case we are actually going to calculate the PARP1 sums across 2KB tiles of the genome.

```{r parp1_abundance}
ln4_cov <- coverage(parp1_ln4_unique, weight = "n_count")
ln5_cov <- coverage(parp1_ln5_unique, weight = "n_count")
genome_tiles <- binned_function(genome_tiles, ln4_cov, "sum", "parp1_r1")
genome_tiles <- binned_function(genome_tiles, ln5_cov, "sum", "parp1_r2")
```

What does this look like for a sample?

```{r sample}
non_zero <- "both"
r1_v_r2 <- subsample_nonzeros(mcols(genome_tiles), c("parp1_r1", "parp1_r2"), non_zero = non_zero, n_points = 10000)

ggplot(r1_v_r2, aes(x = parp1_r1, y = parp1_r2)) + geom_point() + scale_y_log10() + scale_x_log10()
```

Now lets do the orthogonal regression to see the line of best fit between the replicates.

```{r odr}
both_non <- find_non_zeros(mcols(genome_tiles), c("parp1_r1", "parp1_r2"), log_transform = TRUE, non_zero = non_zero)
parp1_data <- mcols(genome_tiles[both_non])
parp1_data[,1] <- log10(parp1_data[,1] + 1)
parp1_data[,2] <- log10(parp1_data[,2] + 1)
parp1_odr <- odregress(parp1_data[,1], parp1_data[,2])
```

Plot everything!

```{r plot_everything}
plot(parp1_data[,1], parp1_data[,2], asp = 1)
lines(parp1_data[,1], parp1_odr$fitted, col = "red")
```

```{r save_parp1_everything, eval=FALSE}
png(file = file.path(graph_dir, "parp1_reps.png")); plot(parp1_data[,1], parp1_data[,2], asp = 1); lines(parp1_data[,1], parp1_odr$fitted, col = "red"); dev.off();
```

#### PARP1 Centile Correlations

```{r parp1_centile_correlation}
parp1_cor_quantiles <- run_cum_quantiles(parp1_data)

odregress_fun <- function(x, y){
  tmp <- pracma::odregress(x, y)
  tmp$coef[1]
}

parp1_odr_quantiles <- run_cum_quantiles(parp1_data, similarity = odregress_fun)
```

```{r plotthem, fig.keep='all'}
p <- ggplot(parp1_cor_quantiles, aes(x = cut, y = cor, color = type)) + geom_point()
print(p)
p + facet_grid(type ~ ., scales = "free")
```

From these plots, we have the ideal case where the correlations actually cross just around 1.25. So we will use 10^1.25 or `r 10^1.25` as our minimum cutoff for the PARP1 data.

## Methylation

```{r load_methyl}
data(methyl_rep1)
data(methyl_rep2)

mcols(methyl_rep1)$methyl_read <- mcols(methyl_rep1)$mcols.readCount * mcols(methyl_rep1)$mcols.percentMeth / 100
mcols(methyl_rep2)$methyl_read <- mcols(methyl_rep2)$mcols.readCount * mcols(methyl_rep2)$mcols.percentMeth / 100

methyl_r1_cov <- coverage(methyl_rep1, weight = "methyl_read")
methyl_r2_cov <- coverage(methyl_rep2, weight = "methyl_read")
genome_tiles <- binned_function(genome_tiles, methyl_r1_cov, "sum", "methyl_r1")
genome_tiles <- binned_function(genome_tiles, methyl_r2_cov, "sum", "methyl_r2")
```

Now plot the methyl ones.

```{r methyl_transform}
methyl_nonzero <- find_non_zeros(mcols(genome_tiles), c("methyl_r1", "methyl_r2"), log_transform = TRUE, non_zero = non_zero)

methyl_data <- mcols(genome_tiles[methyl_nonzero])[,c("methyl_r1", "methyl_r2")]
methyl_data[,1] <- log10(methyl_data[,1] + 1)
methyl_data[,2] <- log10(methyl_data[,2] + 1)
```

```{r methyl_plot}
plot(methyl_data[,1], methyl_data[,2], asp = 1)
```

What does the orthogonal regression look like?

```{r methyl_ord}
methyl_ord <- odregress(methyl_data[,1], methyl_data[,2])
lines(methyl_data[,1], methyl_ord$fitted, col = "red")
```

```{r save_methyl_plot, eval = FALSE}
png(file = file.path(graph_dir, "methyl_reps.png")); plot(methyl_data[,1], methyl_data[,2], asp = 1); lines(methyl_data[,1], methyl_ord$fitted, col = "red"); dev.off();
```

```{r methyl_centiles}
methyl_cor_quantiles <- run_cum_quantiles(methyl_data)
methyl_odr_quantiles <- run_cum_quantiles(methyl_data, similarity = odregress_fun)
```

```{r methyl_plot}
m <- ggplot(methyl_cor_quantiles, aes(x = cut, y = cor, color = type)) + geom_point()
print(m)
m + facet_grid(type ~ ., scales = "free")
```

Unfortunately in this case the lines do not overlap. However, there is a dip in the `hi2low` at ~ 1, and the values for the `low2hi` have started getting above the noise of the low end by ~ 1. So we will use 10^1 or 10 as our cutoff for the methylation reads.

### CTCF

```{r load_ctcf_data}
data(ctcf_rep1)
data(ctcf_rep2)

ctcf_r1_cov <- coverage(ctcf_rep1, weight = "mcols.signal")
ctcf_r2_cov <- coverage(ctcf_rep2, weight = "mcols.signal")

genome_tiles <- binned_function(genome_tiles, ctcf_r1_cov, "mean_nozero", "ctcf_r1")
genome_tiles <- binned_function(genome_tiles, ctcf_r2_cov, "mean_nozero", "ctcf_r2")
```

Find the ones that are non-zero in the replicates

```{r ctcf_nozero}
ctcf_nonzero <- find_non_zeros(mcols(genome_tiles), c("ctcf_r1", "ctcf_r2"), log_transform = TRUE, non_zero = non_zero)

ctcf_data <- mcols(genome_tiles[ctcf_nonzero])[, c("ctcf_r1", "ctcf_r2")]
ctcf_data[,1] <- log10(ctcf_data[,1] + 1)
ctcf_data[,2] <- log10(ctcf_data[,2] + 1)
```

Plot the CTCF data

```{r ctcf_plot}
plot(ctcf_data[,1], ctcf_data[,2], asp = 1)
```

Cool, looks good. Now the cumulative correlations and orthogonal regressions.

```{r ctcf_cum}
ctcf_cor_quantiles <- run_cum_quantiles(ctcf_data)
ctcf_odr_quantiles <- run_cum_quantiles(ctcf_data, similarity = odregress_fun)
```


The midway point is where the correlation is stronger than the noise.
